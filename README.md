# 2018科大讯飞AI营销算法大赛

### 赛题介绍

给定广告、媒体、用户、上下文等方面的信息，预测广告被点击的概率。评价指标是logloss，训练样本跨度为7天，测试集为第8天的样本。初赛复赛的数据集时间重合，只是复赛的样本量比初赛大一倍。比赛采用AB榜同时测评的方式，B榜只在比赛阶段结束后公布，最终成绩以B榜为准。

赛题详细信息：[2018科大讯飞AI营销算法大赛_赛题与数据](http://www.pkbigdata.com/common/cmpt/2018%E7%A7%91%E5%A4%A7%E8%AE%AF%E9%A3%9EAI%E8%90%A5%E9%94%80%E7%AE%97%E6%B3%95%E5%A4%A7%E8%B5%9B_%E8%B5%9B%E4%BD%93%E4%B8%8E%E6%95%B0%E6%8D%AE.html)

最终成绩：初赛31,复赛30。

### 赛题思路

+ 首先是对赛题各字段的具体含义进行理解。通过了解业务背景，以及对数据间关系的分析。知道广告信息上的包含关系为：广告主>活动>订单>广告，广告主又包含了创意。媒体信息上，媒体分类>媒体>频道。而广告位分两种，一种是不属于任何媒体分类或媒体，一种是属于某一个特定的媒体。上下文信息中品牌>机型(这个基本都知道)
+ 整个数据集中creative_is_js/creative_is_voicead/app_paid这三个字段是只有一种取值的，不会对模型训练有任何帮助，应该剔除。creative_is_jump和creative_is_download是互补关系，只需保留一组。advert_id和advert_name除了一组例外，其余都是一一对应的关系，可以理解为有两个广告主同名，因此也只需保留一组，os跟os_name也是同样的关系。
+ 数据集提供的基本都是cate特征。通过前期的EDA分析，发现creative_id、adid、inner_slot_id等对点击率的影响很大，因此该赛题中的id特征很重要，可以考虑往树模型加入id的统计特征，或者是采用FFM等能够处理稀疏特征的模型。
+ 该赛题没有提供userid，除了用户的标签字段外也没有提供任何的用户信息。因此很难挖掘到用户维度的相关信息。对于用户标签，可以考虑直接对标签统计编码后作为特征，或者筛选重要度比较高的标签作为特征。也可以考虑对标签进行压缩编码来表征用户信息。但通过EDA分析统计发现平均每个用户（对user_tags字段去重）只有4条记录，因此对用户的编码可能作用不大。
+ 实际树模型训练中，发现稀疏的id编码特征所占重要性比例异常的高，推测id特征的编码可能有一定规律。经过EDA分析，发现省份跟城市编码基本可以还原回行政区划编码（具体表现为编码的第6位+第9位对应行政区划编码中的2位省份编码，第11、12位为城市的顺序编号。71、72、73代表香港澳门台湾，具体顺序未知。直辖市的城市编码与省份编码相同。普通省份中，推测城市编码与省份编码一致的代表省份已知但城市未知。），但其他id特征没有特别的发现。
+ 对时间进行分析，可以发现不同小时之间点击率有显著差异（凌晨最低，早上较低，下午到晚上较高）。但是在天的维度上，广告的点击率并没有发现明显的差异，可能由于时间周期太短，不足以让广告呈现出点击率上的变化趋势。

### 特征工程

主要有以下4部分：
1. cate编码特征：即对类别特征进行顺序编码后丢入模型。包括数据集中的绝大部分原始特征，一些字段拆分出的前缀特征，相似字段的拼接特征等。
2. 数值型特征：包括极少数数值型的原始特征，时间维度特征（小时、分钟等），id特征中拆分出的有规律的片段特征，对带各种前缀的用户标签的个数统计，各id维度全局范围的数量占比统计，以及两个id维度下的全局范围的数量统计（比如同个app_id下有多少种广告位id）。前期还尝试过时间滑窗统计的各id的历史点击率特征，但是模型效果不好。
3. 用户标签特征：以标签作为特征列构建稀疏矩阵，统计样本中各个标签的出现情况。再根据标签列与label的卡方检验筛选出一部分标签，加入到模型的特征当中。
4. 比较稠密的cate特征onehot：对取值情况少于20的稠密cate特征，对特征进行onehot后加入到模型特征中。
5. 稀疏的cate特征onehot：对取值范围很多的id特征进行onehot，根据卡方检验指标筛选出与label相关度最大的一小部分特征加入到模型特征中。

根据EDA的分析结果，有些特征的空缺值设为空，有些特征的空缺值设置为单独的编号。

### 模型构建

个人总共做了两个模型，一个是自己的lgb单模型，一个是给队友的NFM模型做的lgb残差模型。

**lgb单模型：** 特征即是上述特征工程中的特征，一开始由于采用了时序特征，线上模型一直是用全部训练集训练的单模型。后来丢掉时序特征后，采用的是全部训练集进行5折交叉平均的模型。

**残差模型：** 队友的NFM模型采用的是渣大提供的模型代码（原理及模型见[渣大的github项目](https://github.com/nzc/dnn_ctr)），特征是将原始数据集特征全部作了onehot处理，再加上用户的标签矩阵。原NFM模型复赛A榜误差为0.4243。叠加的LGB残差模型选用的是上述特征工程中的cate编码特征和数值型特征，目标函数采用的是均方差RMSE。由于采用early_stopping确定迭代次数，因此自定义了模型的评价函数：将残差模型输出加上原来NFM的结果，再与click标签计算logloss损失。加上残差结果后如果取值超出0-1范围，则小于0的取原NFM结果的一半，大于0的取NFM结果与1的均值。残差模型后来还尝试过自定义目标函数（即从“NFM结果+残差”改成“对NFM结果反sigmod运算+残差，再对结果取sigmod”），但是效果比均方差略差。

### 模型验证

有两种验证方式：

1. 在前期采用时序特征时，线下模型的训练集取的是前6天的数据，第7天数据随机抽70%作为验证集。该验证方式线下的误差抖动大约是0.0003。
2. 后期没有使用时序特征后，线下主要采用的是5折的CV验证（是LGB自带的CV函数，不是自己写的KFold5折交叉），这种验证方式线下的误差抖动在十万分位，会更稳定一些。缺点就是如果出现时序穿越，那么就可能出现验证结果与线上不同步的情况。
